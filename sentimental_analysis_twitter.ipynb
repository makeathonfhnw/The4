{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet = \"@MehranShakarami today's cold @ home ðŸ˜’ https://mehranshakarami.com\"\n",
    "tweet = 'Great content! subscribed ðŸ˜‰'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precprcess tweet\n",
    "tweet_words = []\n",
    "\n",
    "for word in tweet.split(' '):\n",
    "    if word.startswith('@') and len(word) > 1:\n",
    "        word = '@user'\n",
    "    \n",
    "    elif word.startswith('http'):\n",
    "        word = \"http\"\n",
    "    tweet_words.append(word)\n",
    "\n",
    "tweet_proc = \" \".join(tweet_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and tokenizer\n",
    "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "\n",
    "labels = ['Negative', 'Neutral', 'Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis\n",
    "encoded_tweet = tokenizer(tweet_proc, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yanni\\OneDrive\\FHNW\\Challenges\\MAKEathon\\MaKEathonPostFinance\\sentimental_analysis_twitter.ipynb Zelle 6\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/MAKEathon/MaKEathonPostFinance/sentimental_analysis_twitter.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# output = model(encoded_tweet['input_ids'], encoded_tweet['attention_mask'])\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/MAKEathon/MaKEathonPostFinance/sentimental_analysis_twitter.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m output \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mencoded_tweet)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/MAKEathon/MaKEathonPostFinance/sentimental_analysis_twitter.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m scores \u001b[39m=\u001b[39m output[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/MAKEathon/MaKEathonPostFinance/sentimental_analysis_twitter.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m scores \u001b[39m=\u001b[39m softmax(scores)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/MAKEathon/MaKEathonPostFinance/sentimental_analysis_twitter.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(scores)):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "# output = model(encoded_tweet['input_ids'], encoded_tweet['attention_mask'])\n",
    "output = model(**encoded_tweet)\n",
    "\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "for i in range(len(scores)):\n",
    "    \n",
    "    l = labels[i]\n",
    "    s = scores[i]\n",
    "    print(l,s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
